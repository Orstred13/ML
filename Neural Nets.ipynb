{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import tensorflow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue...l\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    884\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-37d0f0865c89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Continue...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         )\n\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(x_test[i]);\n",
    "    plt.show()\n",
    "    input('Continue...')\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, y_train_d), (_, y_test_d) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 784))\n",
    "x_test = np.reshape(x_test, (len(x_test), 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10 #количество классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение нейросетевой модели\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,), activation='relu')) #скрытый слой\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 104,938\n",
      "Trainable params: 104,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'set_random_seed' from 'tensorflow' (F:\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5b93f46bd3f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'set_random_seed' from 'tensorflow' (F:\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py)"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "import random\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 6.7338 - acc: 0.5766 - val_loss: 5.7015 - val_acc: 0.6423\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 4.7093 - acc: 0.7037 - val_loss: 4.3248 - val_acc: 0.7274\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 4.1962 - acc: 0.7367 - val_loss: 4.1540 - val_acc: 0.7388\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 4.0635 - acc: 0.7448 - val_loss: 3.9962 - val_acc: 0.7493\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 3.9648 - acc: 0.7512 - val_loss: 3.9669 - val_acc: 0.7519\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 3.8070 - acc: 0.7611 - val_loss: 2.8048 - val_acc: 0.8212\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.7395 - acc: 0.8266 - val_loss: 2.5400 - val_acc: 0.8396\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.5499 - acc: 0.8392 - val_loss: 2.4173 - val_acc: 0.8474\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.4584 - acc: 0.8445 - val_loss: 2.5715 - val_acc: 0.8386\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.4332 - acc: 0.8464 - val_loss: 2.4501 - val_acc: 0.8452\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.3622 - acc: 0.8511 - val_loss: 2.4684 - val_acc: 0.8445\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.3762 - acc: 0.8504 - val_loss: 2.4455 - val_acc: 0.8462\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.2804 - acc: 0.8560 - val_loss: 1.5475 - val_acc: 0.9003\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2555 - acc: 0.9188 - val_loss: 1.1019 - val_acc: 0.9289\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.9689 - acc: 0.9377 - val_loss: 0.9214 - val_acc: 0.9404\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.9560 - acc: 0.9383 - val_loss: 0.9263 - val_acc: 0.9399\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.9084 - acc: 0.9417 - val_loss: 0.9937 - val_acc: 0.9367\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.8095 - acc: 0.9478 - val_loss: 0.8816 - val_acc: 0.9435\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.8236 - acc: 0.9471 - val_loss: 0.8754 - val_acc: 0.9435\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.7919 - acc: 0.9489 - val_loss: 0.8952 - val_acc: 0.9426\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.7868 - acc: 0.9493 - val_loss: 0.8273 - val_acc: 0.9466\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.7477 - acc: 0.9517 - val_loss: 0.7558 - val_acc: 0.9519\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.7266 - acc: 0.9534 - val_loss: 0.7216 - val_acc: 0.9537\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.7346 - acc: 0.9528 - val_loss: 0.7977 - val_acc: 0.9491\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.7055 - acc: 0.9548 - val_loss: 0.7250 - val_acc: 0.9537\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.7429 - acc: 0.9523 - val_loss: 0.9006 - val_acc: 0.9427\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.7244 - acc: 0.9537 - val_loss: 0.6983 - val_acc: 0.9552\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.6703 - acc: 0.9572 - val_loss: 0.7564 - val_acc: 0.9522\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.7487 - acc: 0.9525 - val_loss: 0.7887 - val_acc: 0.9500\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.7245 - acc: 0.9538 - val_loss: 0.6889 - val_acc: 0.9565\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.7164 - acc: 0.9543 - val_loss: 0.8427 - val_acc: 0.9464\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.7262 - acc: 0.9537 - val_loss: 0.8242 - val_acc: 0.9472\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.7418 - acc: 0.9529 - val_loss: 0.8411 - val_acc: 0.9469\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.6590 - acc: 0.9582 - val_loss: 0.8204 - val_acc: 0.9478\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.6784 - acc: 0.9569 - val_loss: 0.7209 - val_acc: 0.9543\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.6441 - acc: 0.9592 - val_loss: 0.6996 - val_acc: 0.9559\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.6432 - acc: 0.9593 - val_loss: 0.7099 - val_acc: 0.9554\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.7119 - acc: 0.9549 - val_loss: 0.7284 - val_acc: 0.9532\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.6264 - acc: 0.9602 - val_loss: 0.7834 - val_acc: 0.9503\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.7024 - acc: 0.9557 - val_loss: 0.7528 - val_acc: 0.9522\n",
      "Epoch 41/50\n",
      "34048/48000 [====================>.........] - ETA: 0s - loss: 0.5976 - acc: 0.9619"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train, y_train,o\n",
    "          epochs=50,\n",
    "          batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение нейросетевой модели\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,), activation='sigmoid')) #скрытый слой\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sig = (x_train - x_train.mean()) / x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.821543345689335"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sig.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.1165 - acc: 0.9648 - val_loss: 0.1218 - val_acc: 0.9636\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0902 - acc: 0.9727 - val_loss: 0.1139 - val_acc: 0.9673\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0816 - acc: 0.9755 - val_loss: 0.1122 - val_acc: 0.9667\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0729 - acc: 0.9783 - val_loss: 0.1151 - val_acc: 0.9666\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0662 - acc: 0.9803 - val_loss: 0.1049 - val_acc: 0.9696\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0595 - acc: 0.9829 - val_loss: 0.1030 - val_acc: 0.9691\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.0527 - acc: 0.9851 - val_loss: 0.1004 - val_acc: 0.9703\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0474 - acc: 0.9868 - val_loss: 0.1006 - val_acc: 0.9700\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0427 - acc: 0.9887 - val_loss: 0.0964 - val_acc: 0.9709\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0370 - acc: 0.9909 - val_loss: 0.0983 - val_acc: 0.9705\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0330 - acc: 0.9919 - val_loss: 0.0991 - val_acc: 0.9709\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.0290 - acc: 0.9933 - val_loss: 0.0957 - val_acc: 0.9727\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.0252 - acc: 0.9946 - val_loss: 0.0992 - val_acc: 0.9717\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0221 - acc: 0.9954 - val_loss: 0.0959 - val_acc: 0.9723\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0191 - acc: 0.9964 - val_loss: 0.0954 - val_acc: 0.9733\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0164 - acc: 0.9972 - val_loss: 0.0954 - val_acc: 0.9743\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0144 - acc: 0.9975 - val_loss: 0.0949 - val_acc: 0.9740\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.0121 - acc: 0.9982 - val_loss: 0.0990 - val_acc: 0.9727\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 4s 79us/step - loss: 0.0102 - acc: 0.9985 - val_loss: 0.0982 - val_acc: 0.9743\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.0973 - val_acc: 0.9753\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.0074 - acc: 0.9991 - val_loss: 0.0990 - val_acc: 0.9740\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.1004 - val_acc: 0.9743\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0060 - acc: 0.9993 - val_loss: 0.1054 - val_acc: 0.9745\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0042 - acc: 0.9997 - val_loss: 0.1056 - val_acc: 0.9743\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.1027 - val_acc: 0.9740\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.1099 - val_acc: 0.9723\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.0024 - acc: 0.9999 - val_loss: 0.1041 - val_acc: 0.9748\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9760\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9757\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9751\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9755\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.1672 - val_acc: 0.9594\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0217 - acc: 0.9929 - val_loss: 0.1147 - val_acc: 0.9738\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.1114 - val_acc: 0.9758\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9763\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 9.3676e-04 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9763\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 7.8164e-04 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9762\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 6.8842e-04 - acc: 1.0000 - val_loss: 0.1124 - val_acc: 0.9759\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 6.0922e-04 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9759\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 5.4723e-04 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9756\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 4.9117e-04 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9755\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 4.3541e-04 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9756\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 3.8817e-04 - acc: 1.0000 - val_loss: 0.1145 - val_acc: 0.9758\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 3.4845e-04 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9758\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 3.0771e-04 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9759\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 2.7897e-04 - acc: 1.0000 - val_loss: 0.1178 - val_acc: 0.9763\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 2.4198e-04 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9758\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 2.1536e-04 - acc: 1.0000 - val_loss: 0.1198 - val_acc: 0.9758\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 1.9037e-04 - acc: 1.0000 - val_loss: 0.1202 - val_acc: 0.9761\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 1.6229e-04 - acc: 1.0000 - val_loss: 0.1223 - val_acc: 0.9758\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d67b772ac8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train_sig, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR PART AND CONV NETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 439s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.reshape(x_train, (len(x_train), 32*32*3))\n",
    "# x_test = np.reshape(x_test, (len(x_test), 32*32*3))\n",
    "\n",
    "n_classes = 10 #количество классов\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sig = (x_train - x_train.mean()) / x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение нейросетевой модели\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(3072,), activation='relu')) #скрытый слой\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 397,802\n",
      "Trainable params: 397,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_sig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_sig' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train_sig, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение нейросетевой модели\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 215,562\n",
      "Trainable params: 215,498\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 2.2724 - accuracy: 0.1658 - val_loss: 2.1328 - val_accuracy: 0.2038\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 1.9934 - accuracy: 0.2607 - val_loss: 2.0193 - val_accuracy: 0.2698\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.7271 - accuracy: 0.3377 - val_loss: 1.7826 - val_accuracy: 0.3464\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.4915 - accuracy: 0.4526 - val_loss: 2.1349 - val_accuracy: 0.3457\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 1.3638 - accuracy: 0.5023 - val_loss: 2.1751 - val_accuracy: 0.3707\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.2814 - accuracy: 0.5351 - val_loss: 2.0852 - val_accuracy: 0.3932\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.2180 - accuracy: 0.5571 - val_loss: 2.5435 - val_accuracy: 0.3589\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 1.1718 - accuracy: 0.5765 - val_loss: 2.4922 - val_accuracy: 0.3885\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.1340 - accuracy: 0.5905 - val_loss: 1.8750 - val_accuracy: 0.4726\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 1.0926 - accuracy: 0.6081 - val_loss: 1.8725 - val_accuracy: 0.4768\n",
      "Wall time: 11min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f7afc4d888>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 412us/step\n",
      "[1.8416384418487548, 0.4742000102996826]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=256)\n",
    "print(score)\n",
    "\n",
    "# model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequantial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-49a4c1996521>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvgg_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequantial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg_conv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequantial' is not defined"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size,3))\n",
    "\n",
    "model = Sequantial()\n",
    "\n",
    "model.add(vgg_conv)\n",
    "mode.add(Flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
